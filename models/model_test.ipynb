{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "conda-env-ML-py",
   "display_name": "Python [conda env:ML] *",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bilstm = nn.LSTM(input_size=1, hidden_size=2, num_layers=1, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.1568,  0.3701,  1.2371, -1.2127]],\n",
       "\n",
       "        [[-0.4818,  1.3980, -0.1983, -0.2674]],\n",
       "\n",
       "        [[ 0.7368,  0.9752, -1.3589, -0.1075]],\n",
       "\n",
       "        [[ 0.1641,  1.0206, -2.4703,  1.4388]],\n",
       "\n",
       "        [[-0.5479, -0.2959, -2.2385, -0.8678]]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "input = t.randn(5, 1, 4)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Bilstm(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "result[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "result[1][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(in_features=4 * 2 * 2, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_input = result[0].reshape(5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2010],\n",
       "        [0.2005],\n",
       "        [0.2059],\n",
       "        [0.1561],\n",
       "        [0.1130]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "fc(fc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0671, -0.0777, -0.1432, -0.2131,  0.0172, -0.0949, -0.1220, -0.1665,\n",
       "          0.0782, -0.1187, -0.1270, -0.0792, -0.0588, -0.0093, -0.0569,  0.0400],\n",
       "        [-0.0618,  0.0146, -0.1132, -0.1894,  0.0623, -0.0758, -0.1470, -0.1851,\n",
       "         -0.0274, -0.0638, -0.1070, -0.1327, -0.0530, -0.0502, -0.0699, -0.0761],\n",
       "        [ 0.0298, -0.0660, -0.1382, -0.1866,  0.0606, -0.1044, -0.1467, -0.1097,\n",
       "         -0.0648,  0.0188, -0.0840,  0.0048, -0.0666, -0.0084, -0.0721, -0.0870],\n",
       "        [-0.0204, -0.0370, -0.1234, -0.1055,  0.0489, -0.0915, -0.1412,  0.0257,\n",
       "         -0.0686,  0.1505, -0.0585,  0.1970,  0.0506, -0.0341, -0.0896, -0.0952],\n",
       "        [-0.0648,  0.0209, -0.1230, -0.0622, -0.0735,  0.0094, -0.1204,  0.0281,\n",
       "         -0.1007,  0.2084, -0.0657,  0.2011, -0.1361,  0.1833, -0.0616, -0.0120]],\n",
       "       grad_fn=<UnsafeViewBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "result[0].reshape(result[0].shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "result[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bicut(nn.Module):\n",
    "    def __init__(self, seq_len=300, input_size=1, lstm_hiden_size=128, lstm_layers=2, lstm_dropout=0.4, fc_dimensions=256):\n",
    "        super(Bicut, self).__init__()\n",
    "        self.Bilstm = nn.LSTM(input_size=input_size, hidden_size=lstm_hiden_size, num_layers=lstm_layers,\n",
    "                              batch_first=True, dropout=lstm_dropout, bidirectional=True)\n",
    "        self.FC = nn.Linear(in_features=seq_len *lstm_hiden_size * 2, out_features=fc_dimensions)\n",
    "        self.Softmax = nn.Sequential(\n",
    "            nn.Linear(in_features=fc_dimensions, out_features=2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.Bilstm(x)[0]\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = t.sigmoid(self.FC(x))\n",
    "        return self.Softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([194, 300, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "model = Bicut()\n",
    "input = t.randn(194, 300, 1)\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([194, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "result = model.forward(input)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "test_i = t.randn(5, 2, 16)\n",
    "fc(test_i).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}