{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRMM result相关的训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<bound method NDFrame.head of           0  1                 2    3         4     5\n",
      "0       301  0       FBIS4-46734    0  6.859538  drmm\n",
      "1       301  0       FBIS4-39330    1  6.754804  drmm\n",
      "2       301  0        FBIS4-7811    2  6.686247  drmm\n",
      "3       301  0       FBIS3-24145    3  6.658622  drmm\n",
      "4       301  0       FBIS3-23986    4  6.445690  drmm\n",
      "...     ... ..               ...  ...       ...   ...\n",
      "241388  700  0       FBIS3-31959  995  2.720761  drmm\n",
      "241389  700  0  FR940921-0-00153  996  2.718753  drmm\n",
      "241390  700  0     LA110490-0093  997  2.718751  drmm\n",
      "241391  700  0     LA122889-0096  998  2.717326  drmm\n",
      "241392  700  0     LA102690-0197  999  2.715926  drmm\n",
      "\n",
      "[241393 rows x 6 columns]>\n",
      "(249,)\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_table('./drmm_results/result_grissom_rerank.txt',sep='\\t',header=None)\n",
    "pprint(type(result))\n",
    "pprint(result.head)\n",
    "pprint(result[0].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158790,)\n"
     ]
    }
   ],
   "source": [
    "pprint(result[2].unique().shape)  # 共有158790篇不同的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./robust04_data/docset_fbis5.pkl', 'rb') as f: docset_fbis5 = pickle.load(f)\n",
    "with open('./robust04_data/docset_fr94.pkl', 'rb') as f: docset_fr94 = pickle.load(f)\n",
    "with open('./robust04_data/docset_ft.pkl', 'rb') as f: docset_ft = pickle.load(f)\n",
    "with open('./robust04_data/docset_latimes.pkl', 'rb') as f: docset_latimes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docset = docset_fbis5\n",
    "docset.update(docset_fr94)\n",
    "docset.update(docset_ft)\n",
    "docset.update(docset_latimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./docset.pkl', 'wb') as f:\n",
    "    pickle.dump(docset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528155"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for item in list_1: \n",
    "    if item not in set_2: count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1000\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "rank = list(result[3])\n",
    "count = 0  # 统计索引条目少于300的topic\n",
    "for i in range(len(rank)-900):\n",
    "    if rank[i] > rank[i+1]:\n",
    "        length.append(rank[i]+1)\n",
    "        if length[-1] < 300:\n",
    "            count += 1\n",
    "print(min(length), max(length))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 制作DRMM数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_dataset(all_data: dict, train_ratio=0.8, seed=1):\n",
    "    \"\"\"\n",
    "    随机划分数据集\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    train_size = int(len(all_data) * train_ratio)\n",
    "    train_set, test_set, key_list = {}, {}, list(all_data.keys())\n",
    "    for i in range(train_size):\n",
    "        random_index = random.randint(0, len(key_list) - 1)\n",
    "        train_set[key_list[random_index]] = all_data[key_list[random_index]]\n",
    "        key_list.pop(random_index)\n",
    "    for key in key_list: test_set[key] = all_data[key]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "for index, row in result.iterrows():\n",
    "    if str(row[0]) not in all_data: all_data[str(row[0])], count = {row[3]: {'doc_id':row[2] , 'score': row[4]}}, 1\n",
    "    elif count >= 300: continue\n",
    "    else: \n",
    "        all_data[str(row[0])].update({row[3]: {'doc_id':row[2] , 'score': row[4]}})\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in list(all_data.keys()):\n",
    "    if len(all_data[key]) < 300: del all_data[key]\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "# 统计一个相关文档都没有的ranked list\n",
    "doc0count = 0\n",
    "for key in list(all_data.keys()):\n",
    "    count = 0\n",
    "    for index in all_data[key]:\n",
    "        if all_data[key][index]['doc_id'] in gt[key]:\n",
    "            count += 1\n",
    "            break\n",
    "    if count == 0: \n",
    "        doc0count += 1\n",
    "        del all_data[key]\n",
    "print(doc0count)\n",
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 生成5-fold数据集\n",
    "for i in range(1, 6):\n",
    "    train_set, test_set = split_dataset(all_data, seed=i)\n",
    "    if not os.path.exists('./drmm_results_clean/split_{}/'.format(i)): os.makedirs('./drmm_results_clean/split_{}/'.format(i))\n",
    "    with open('./drmm_results_clean/split_{}/drmm_train_s{}.pkl'.format(i, i), 'wb') as f: \n",
    "        pickle.dump(train_set, f)\n",
    "    with open('./drmm_results_clean/split_{}/drmm_test_s{}.pkl'.format(i, i), 'wb') as f: \n",
    "        pickle.dump(test_set, f)\n",
    "with open('./drmm_results_clean/DRMM_all.pkl', 'wb') as f: pickle.dump(all_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRMM结果统计\n",
    "* 可见模型结果一共包含249个topic的结果（少了一个，但是问题不大）\n",
    "* 结果条目数最少是6，最大是1000\n",
    "* 共有243个结果条目数大于等于300的topic，可以用作序列截断任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文档相关的输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取topic与对应的相关文档的数据字典\n",
    "with open('robust04_data/split_1/rob04_bm25_top1000.train.s1.pkl', 'rb') as f:\n",
    "    train_s1 = pickle.load(f)\n",
    "with open('robust04_data/split_1/rob04_bm25_top1000.dev.s1.pkl', 'rb') as f:\n",
    "    dev_s1 = pickle.load(f)\n",
    "with open('robust04_data/split_1/rob04_bm25_top1000.test.s1.pkl', 'rb') as f:\n",
    "    test_s1 = pickle.load(f)\n",
    "\n",
    "# 提取原文档的描述信息字典\n",
    "with open('robust04_data/split_1/rob04_bm25_docset_top1000.train.s1.pkl', 'rb') as f:\n",
    "    train_s1_doc = pickle.load(f)\n",
    "with open('robust04_data/split_1/rob04_bm25_docset_top1000.dev.s1.pkl', 'rb') as f:\n",
    "    dev_s1_doc = pickle.load(f)\n",
    "with open('robust04_data/split_1/rob04_bm25_docset_top1000.test.s1.pkl', 'rb') as f:\n",
    "    test_s1_doc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['query_id', 'query_text', 'relevant_documents', 'num_rel', 'retrieved_documents', 'num_ret', 'num_rel_ret'])\n",
      "['FR940527-1-00246',\n",
      " 'FT924-3705',\n",
      " 'FT923-13842',\n",
      " 'FT924-13624',\n",
      " 'LA021190-0103',\n",
      " 'FT931-12873',\n",
      " 'FT941-9456',\n",
      " 'FR941221-2-00097',\n",
      " 'FR940119-1-00020',\n",
      " 'LA120190-0121']\n",
      "dict_keys(['title', 'abstractText']) 115502\n"
     ]
    }
   ],
   "source": [
    "pprint(train_s1['queries'][0].keys())\n",
    "pprint(list(train_s1_doc.keys())[:10])  # 展示前10个文档标号\n",
    "print(train_s1_doc['FR940527-1-00246'].keys(), len(train_s1_doc))  # 展示每一个文档的描述信息键值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SGA/DAA 94&hyph;24, Local Learning Laboratory   Budget Detail Sheet       Applicant:       &blank;   1Category   2&blank;   1Year 1   2Federal funds requested   2Non-Federal funds      Service Delivery Budget:    Reflects planned improvements in access and method of delivery of services to benefit the customer.  &blank;  &blank;    Program/Service Integration Budget:    Reflects additional programs/services to be integrated into the local One-Stop system.  &blank;  &blank;     Hardware Budget:    Reflects hardware acquisitions for programmatic, direct customer service, and labor market information purposes.  &blank;  &blank;     Software Budget:    Reflects software enhancements to improve case management and/or delivery of services (including conveyance of labor market information).  &blank;  &blank;     Space and Premises Budget:    Reflects reconfiguration and upgrading of space to create an office environment more ``user friendly'' and attractive to customers.  &blank;  &blank;      Testing and Evaluation Budget:    Reflects testing and evaluating innovations in One-Stop system delivery.  &blank;  &blank;     Marketing/Dissemination Budget:    Reflects staff and material costs for marketing/dissemination activities.  &blank;  &blank;     Training Budget:    Specialized staff training to achieve system delivery, integration, technology (hardware and software), testing and evaluation, marketing/dissemination activities.  &blank;  &blank;  n,s    Total  &blank;  &blank;            [FR Doc. 94&hyph;31294 Filed 12&hyph;20&hyph;94; 8:45 am]       BILLING CODE 4510&hyph;30&hyph;M      \n"
     ]
    }
   ],
   "source": [
    "print(train_s1_doc['FR941221-2-00097']['abstractText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成文档相关的统计数据和表征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sga daa        local learning laboratory   budget detail sheet       applicant             category         year      federal funds requested    non federal funds      service delivery budget     reflects planned improvements in access and method of delivery of services to benefit the customer          program service integration budget     reflects additional programs services to be integrated into the local one stop system           hardware budget     reflects hardware acquisitions for programmatic  direct customer service  and labor market information purposes           software budget     reflects software enhancements to improve case management and or delivery of services  including conveyance of labor market information            space and premises budget     reflects reconfiguration and upgrading of space to create an office environment more   user friendly and attractive to customers            testing and evaluation budget     reflects testing and evaluating innovations in one stop system delivery           marketing dissemination budget     reflects staff and material costs for marketing dissemination activities           training budget     specialized staff training to achieve system delivery  integration  technology  hardware and software   testing and evaluation  marketing dissemination activities        n s    total                   fr doc          filed                am        billing code         m\n"
     ]
    }
   ],
   "source": [
    "test_text = 'SGA/DAA 94&hyph;24, Local Learning Laboratory   Budget Detail Sheet       Applicant:       &blank;   1Category   2&blank;   1Year 1   2Federal funds requested   2Non-Federal funds      Service Delivery Budget:    Reflects planned improvements in access and method of delivery of services to benefit the customer.  &blank;  &blank;    Program/Service Integration Budget:    Reflects additional programs/services to be integrated into the local One-Stop system.  &blank;  &blank;     Hardware Budget:    Reflects hardware acquisitions for programmatic, direct customer service, and labor market information purposes.  &blank;  &blank;     Software Budget:    Reflects software enhancements to improve case management and/or delivery of services (including conveyance of labor market information).  &blank;  &blank;     Space and Premises Budget:    Reflects reconfiguration and upgrading of space to create an office environment more ``user friendly'' and attractive to customers.  &blank;  &blank;      Testing and Evaluation Budget:    Reflects testing and evaluating innovations in One-Stop system delivery.  &blank;  &blank;     Marketing/Dissemination Budget:    Reflects staff and material costs for marketing/dissemination activities.  &blank;  &blank;     Training Budget:    Specialized staff training to achieve system delivery, integration, technology (hardware and software), testing and evaluation, marketing/dissemination activities.  &blank;  &blank;  n,s    Total  &blank;  &blank;            [FR Doc. 94&hyph;31294 Filed 12&hyph;20&hyph;94; 8:45 am]       BILLING CODE 4510&hyph;30&hyph;M'\n",
    "# test_text = train_s1_doc['FR941221-2-00097']['abstractText']\n",
    "clean = lambda t: re.sub('[,?;*!%^&_+():\\[\\]{}`~@#$=+\\\\|/<>.\\'\\\"\\d]', ' ', t.replace('\"', ' ').replace('/', ' ').replace('\\\\', ' ').replace(\"'\", ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('-', ' ').replace('.', '').replace('&hyph;', ' ').replace('&blank;', ' ').strip().lower())\n",
    "preprocessed_text = clean(test_text)\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "test_list = [word for word in preprocessed_text.lower().split() if word not in stoplist]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for token in test_list:\n",
    "    frequency[token] += 1\n",
    "\n",
    "texts = [token for token in test_list if frequency[token] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['local', 'budget', 'federal', 'funds', 'federal', 'funds', 'service', 'delivery', 'budget', 'reflects', 'delivery', 'services', 'customer', 'service', 'integration', 'budget', 'reflects', 'services', 'local', 'one', 'stop', 'system', 'hardware', 'budget', 'reflects', 'hardware', 'customer', 'service', 'labor', 'market', 'information', 'software', 'budget', 'reflects', 'software', 'delivery', 'services', 'labor', 'market', 'information', 'space', 'budget', 'reflects', 'space', 'testing', 'evaluation', 'budget', 'reflects', 'testing', 'one', 'stop', 'system', 'delivery', 'marketing', 'dissemination', 'budget', 'reflects', 'staff', 'marketing', 'dissemination', 'activities', 'training', 'budget', 'staff', 'training', 'system', 'delivery', 'integration', 'hardware', 'software', 'testing', 'evaluation', 'marketing', 'dissemination', 'activities']\n"
     ]
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将所有文档清洗转换为token列表之后，可以使用gensim操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本清洗函数\n",
    "def clean_texts(texts, stoplist):\n",
    "    clean = lambda t: re.sub('[,?;*!%^&_+():\\[\\]{}`~@#$=+\\\\|/<>.\\'\\\"\\d]', ' ', t.replace('\"', ' ').replace('/', ' ').replace('\\\\', ' ').replace(\"'\", ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('-', ' ').replace('.', '').replace('&hyph;', ' ').replace('&blank;', ' ').strip().lower())\n",
    "    preprocessed_text = clean(texts)\n",
    "    text_list = [word for word in preprocessed_text.lower().split() if word not in stoplist]\n",
    "    # remove words that appear only once\n",
    "    frequency = defaultdict(int)\n",
    "    for token in text_list:\n",
    "        frequency[token] += 1\n",
    "    clean_texts = [token for token in frequency if frequency[token] > 1]\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'FT  10 DEC 93 / UK Company News: Standard Chartered in Pounds 100m\\npreference issue',\n",
       " 'abstractText': \"Standard Chartered, the UK-based international banking group, yesterday\\nstrengthened its capital base with a Pounds 100m issue of non-cumulative\\npreference shares, writes John Gapper. The issue raises its core tier 1\\nratio of capital to risk-weighted assets.\\nStandard's share price has risen sharply recently, driven by its exposure to\\nemerging markets in the Asia Pacific region. But there has been speculation\\nover whether it would be forced into a rights issue to strengthen capital.\\nThe bank is also exposed to the appreciation of the dollar against sterling\\nbecause its capital is sterling-denominated, while most of its assets are in\\ncurrencies which are more closely linked to the dollar.\\nIt has had a lower ratio of tier 1 capital - comprising equity, risk capital\\nincluding non-cumulative preference shares, and retained earnings - to its\\nrisk-weighted assets than many US and European banks.\\nThe issue, which was jointly placed by J Henry Schroder Wagg, Cazenove and\\nSalamon Brothers, will raise its tier 1 ratio of 5.4 per cent by 50 basis\\npoints, and its total capital ratio of 10.7 per cent by a percentage point.\\nA sterling rather than a dollar issue is thought to have been chosen because\\nof regulatory requirements in the US, and because dollar preference shares\\nwould only provide a limited hedge against currency movements.\\nNon-cumulative preference shares are counted by the Bank of England towards\\nregulatory tier 1 capital because they are considered to carry investor\\nrisk. The issue was placed at a net yield of 7.375 per cent.\\nThe shares lost 8p to 1229p.\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docset['FT934-3024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528155"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据docset生成corpus\n",
    "corpus = []\n",
    "for key in docset:\n",
    "    texts = docset[key]['title'] + docset[key]['abstractText']\n",
    "    document = clean_texts(texts, stoplist)\n",
    "    corpus.append(document)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果保存到pkl文件中\n",
    "with open('./corpus.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成BM25结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./robust04_data/split_1/rob04_bm25_top1000.train.s1.pkl', 'rb') as f: bm25_train = pickle.load(f)\n",
    "with open('./robust04_data/split_1/rob04_bm25_top1000.dev.s1.pkl', 'rb') as f: bm25_dev = pickle.load(f)\n",
    "with open('./robust04_data/split_1/rob04_bm25_top1000.test.s1.pkl', 'rb') as f: bm25_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10): \n",
    "    print(bm25_test['queries'][0]['retrieved_documents'][i]['is_relevant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bm25_train['queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = bm25_train['queries'] + bm25_dev['queries'] + bm25_test['queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query_id', 'query_text', 'relevant_documents', 'num_rel', 'retrieved_documents', 'num_ret', 'num_rel_ret'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_set = set()\n",
    "for i in range(250): aux_set.add(bm25[i]['query_id'])\n",
    "len(aux_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FBIS3-10082'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25[0]['relevant_documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 'FBIS4-41991',\n",
       " 'rank': 3,\n",
       " 'bm25_score': 5.63055377,\n",
       " 'norm_bm25_score': 3.1348520653230927,\n",
       " 'is_relevant': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25[0]['retrieved_documents'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25[0]['num_ret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_dataset = {}\n",
    "for item in bm25: \n",
    "    if len(item['retrieved_documents']) >=300: bm25_dataset[item['query_id']] = {'query_text': item['query_text'], 'retrieved_documents': item['retrieved_documents'][:300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "241\n"
     ]
    }
   ],
   "source": [
    "# 统计一个相关文档都没有的ranked list\n",
    "doc0count = 0\n",
    "for key in list(bm25_dataset.keys()):\n",
    "    count = 0\n",
    "    for ret_doc in bm25_dataset[key]['retrieved_documents']:\n",
    "        # if ret_doc['doc_id'] in gt[key]:\n",
    "        if ret_doc['is_relevant']: \n",
    "            count += 1\n",
    "            break\n",
    "    if count == 0: \n",
    "        doc0count += 1\n",
    "        del bm25_dataset[key]\n",
    "print(doc0count)\n",
    "print(len(bm25_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 生成5-fold数据集\n",
    "for i in range(1, 6):\n",
    "    train_set, test_set = split_dataset(bm25_dataset, seed=i)\n",
    "    if not os.path.exists('./BM25_results_clean/split_{}/'.format(i)): os.makedirs('./BM25_results_clean/split_{}/'.format(i))\n",
    "    with open('./BM25_results_clean/split_{}/BM25_train_s{}.pkl'.format(i, i), 'wb') as f: \n",
    "        pickle.dump(train_set, f)\n",
    "    with open('./BM25_results_clean/split_{}/BM25_test_s{}.pkl'.format(i, i), 'wb') as f: \n",
    "        pickle.dump(test_set, f)\n",
    "with open('./BM25_results_clean/BM25_all.pkl', 'wb') as f:\n",
    "    pickle.dump(bm25_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./BM25_results/split_1/BM25_train_s1.pkl', 'rb') as f: tr1 = pickle.load(f)\n",
    "with open('./BM25_results/split_2/BM25_train_s2.pkl', 'rb') as f: tr2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['368', '307', '429', '339', '305', '338', '414', '365', '669', '318', '654', '664', '611', '625', '419', '400', '357', '679', '325', '647', '636', '655', '436', '424', '432', '301', '304', '666', '433', '347', '657', '411', '443', '363', '607', '328', '321', '331', '696', '379', '310', '646', '389', '416', '675', '622', '334', '407', '423', '689', '352', '630', '434', '641', '435', '610', '426', '337', '614', '332', '690', '674', '450', '375', '408', '449', '627', '384', '649', '632', '329', '651', '412', '637', '624', '425', '662', '673', '700', '616', '341', '639', '602', '342', '371', '406', '687', '439', '694', '373', '618', '326', '383', '405', '420', '377', '319', '324', '336', '309', '353', '660', '422', '421', '427', '633', '613', '315', '447', '629', '672', '698', '346', '386', '608', '653', '320', '659', '685', '695', '626', '303', '446', '308', '621', '370', '684', '676', '648', '391', '367', '665', '330', '682', '392', '620', '350', '656', '448', '343', '314', '393', '680', '634', '671', '603', '642', '445', '306', '431', '605', '322', '317', '444', '688', '323', '335', '402', '681', '390', '683', '604', '395', '362', '361', '437', '345', '360', '372', '333', '619', '327', '617', '606', '631', '387', '415', '340', '658', '374', '381', '382', '401', '667', '385', '601', '410', '640', '699', '430', '645', '413', '441', '693'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['439', '425', '335', '355', '353', '613', '429', '387', '696', '413', '619', '623', '441', '415', '379', '402', '397', '328', '352', '673', '384', '655', '630', '641', '622', '324', '690', '634', '340', '665', '693', '433', '331', '325', '636', '685', '609', '645', '667', '377', '393', '605', '398', '423', '421', '321', '400', '629', '399', '381', '428', '431', '654', '601', '608', '676', '406', '319', '687', '651', '659', '326', '653', '660', '343', '395', '688', '417', '657', '699', '445', '640', '614', '672', '677', '304', '666', '436', '618', '664', '449', '420', '611', '683', '434', '646', '401', '612', '308', '643', '638', '370', '652', '424', '389', '371', '648', '427', '361', '616', '307', '358', '682', '306', '416', '373', '351', '344', '637', '603', '376', '394', '649', '625', '447', '357', '606', '621', '632', '302', '315', '334', '440', '442', '374', '404', '661', '313', '350', '363', '341', '327', '336', '391', '310', '631', '426', '380', '698', '390', '633', '408', '356', '450', '301', '670', '305', '354', '444', '396', '345', '303', '671', '432', '628', '385', '635', '679', '662', '359', '668', '443', '419', '692', '365', '627', '378', '414', '318', '615', '383', '700', '405', '360', '330', '418', '697', '674', '684', '337', '382', '604', '602', '435', '437', '346', '658', '639', '333', '322', '342', '388', '323', '366'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {}\n",
    "for item in bm25: gt[item['query_id']] = item['relevant_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./robust04_gt.pkl', 'wb') as f:\n",
    "    pickle.dump(gt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./drmm_results/DRMM_all.pkl', 'rb') as f: drmm_all = pickle.load(f)\n",
    "with open('./BM25_results/BM25_all.pkl', 'rb') as f: bm25_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FBIS4-46734', 'FBIS4-39330', 'FBIS4-7811', 'FBIS3-24145', 'FBIS3-23986']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drmm_ranked_list = {}\n",
    "for key in drmm_all: drmm_ranked_list[key] = [drmm_all[key][index]['doc_id'] for index in drmm_all[key]]\n",
    "drmm_ranked_list['301'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FBIS3-21961', 'LA112489-0141', 'FBIS4-41991', 'LA121990-0141', 'FBIS4-19535']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_ranked_list = {}\n",
    "for key in bm25_all: bm25_ranked_list[key] = [bm25_all[key]['retrieved_documents'][i]['doc_id'] for i in range(300)]\n",
    "bm25_ranked_list['301'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./drmm_ranked_list.json', 'w') as f: json.dump(drmm_ranked_list, f)\n",
    "with open('./bm25_ranked_list.json', 'w') as f: json.dump(bm25_ranked_list, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对matchzoo的结果制作ranked list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>id_right</th>\n",
       "      <th>label</th>\n",
       "      <th>relation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434</td>\n",
       "      <td>FBIS4-62284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.472672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>FBIS4-17334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.677305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408</td>\n",
       "      <td>LA090889-0108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.801664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>FR940810-0-00217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.566301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>663</td>\n",
       "      <td>FT941-9723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.963085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_left          id_right  label  relation_score\n",
       "0     434       FBIS4-62284    1.0        5.472672\n",
       "1     627       FBIS4-17334    0.0       -1.677305\n",
       "2     408     LA090889-0108    0.0       -9.801664\n",
       "3     347  FR940810-0-00217    0.0       -4.566301\n",
       "4     663        FT941-9723    0.0       -4.963085"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('information retrieval/robust04/matchzoo/results/drmm_tks.pkl', 'rb') as f: tks_all = pickle.load(f)\n",
    "tks_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tks_all.sort_values(by=['id_left'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>id_right</th>\n",
       "      <th>label</th>\n",
       "      <th>relation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175761</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-37399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.958324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136069</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-10513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.961651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147589</th>\n",
       "      <td>301</td>\n",
       "      <td>LA121290-0151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.406104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164235</th>\n",
       "      <td>301</td>\n",
       "      <td>FT934-2699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.071196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88028</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-13584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.790793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_left       id_right  label  relation_score\n",
       "175761     301    FBIS3-37399    0.0       -9.958324\n",
       "136069     301    FBIS3-10513    0.0       -7.961651\n",
       "147589     301  LA121290-0151    0.0       -7.406104\n",
       "164235     301     FT934-2699    0.0       -9.071196\n",
       "88028      301    FBIS3-13584    0.0       -8.790793"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tks_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tks_all[tks_all['id_left'] == '301'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>id_right</th>\n",
       "      <th>label</th>\n",
       "      <th>relation_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166166</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-41131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.436135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104024</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-41212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.268208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109656</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-41349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.176438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27215</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS4-7811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.106179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71371</th>\n",
       "      <td>301</td>\n",
       "      <td>FBIS3-41293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.937361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_left     id_right  label  relation_score\n",
       "166166     301  FBIS3-41131    1.0        6.436135\n",
       "104024     301  FBIS3-41212    1.0        6.268208\n",
       "109656     301  FBIS3-41349    1.0        6.176438\n",
       "27215      301   FBIS4-7811    1.0        6.106179\n",
       "71371      301  FBIS3-41293    1.0        5.937361"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tks_all[tks_all['id_left'] == '301'].sort_values(by=['relation_score'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['301', '302', '303']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = list(pd.unique(tks_all['id_left']))\n",
    "queries[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tks_ranked_list = {}\n",
    "for query in queries:\n",
    "    tks_ranked_list[query] = []\n",
    "    qerls_df = tks_all[tks_all['id_left'] == query].sort_values(by=['relation_score'], ascending=False)\n",
    "    for row in qerls_df.iterrows():\n",
    "        tks_ranked_list[query].append({'doc_id': row[1]['id_right'], 'score': row[1]['relation_score']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = {}\n",
    "for key in tks_ranked_list:\n",
    "    if len(tks_ranked_list[key]) >= 300: all_data[key] = tks_ranked_list[key][:300]\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_dataset(all_data: dict, train_ratio=0.8, seed=1):\n",
    "    \"\"\"\n",
    "    随机划分数据集\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    train_size = int(len(all_data) * train_ratio)\n",
    "    train_set, test_set, key_list = {}, {}, list(all_data.keys())\n",
    "    for i in range(train_size):\n",
    "        random_index = random.randint(0, len(key_list) - 1)\n",
    "        train_set[key_list[random_index]] = all_data[key_list[random_index]]\n",
    "        key_list.pop(random_index)\n",
    "    for key in key_list: test_set[key] = all_data[key]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 生成5-fold数据集\n",
    "for i in range(1, 6):\n",
    "    train_set, test_set = split_dataset(all_data, seed=i)\n",
    "    if not os.path.exists('./ranked list truncation/data_prep/my_results/drmm_tks_results/split_{}/'.format(i)): os.makedirs('./ranked list truncation/data_prep/my_results/drmm_tks_results/split_{}/'.format(i))\n",
    "    with open('./ranked list truncation/data_prep/my_results/drmm_tks_results/split_{}/drmm_tks_train_s{}.pkl'.format(i, i), 'wb') as f: pickle.dump(train_set, f)\n",
    "    with open('./ranked list truncation/data_prep/my_results/drmm_tks_results/split_{}/drmm__tks_test_s{}.pkl'.format(i, i), 'wb') as f: pickle.dump(test_set, f)\n",
    "with open('./ranked list truncation/data_prep/my_results/drmm_tks_results/DRMM_TKS_all.pkl', 'wb') as f: pickle.dump(all_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
