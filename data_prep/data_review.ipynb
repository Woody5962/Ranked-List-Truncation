{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需的排序列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranked list truncation/dataset/drmm_train.pkl', 'rb') as f:\n",
    "    drmm_train = pickle.load(f)\n",
    "with open('./ranked list truncation/dataset/drmm_test.pkl', 'rb') as f:\n",
    "    drmm_test = pickle.load(f)\n",
    "with open('./ranked list truncation/dataset/bm25_train.pkl', 'rb') as f:\n",
    "    bm25_train = pickle.load(f)\n",
    "with open('./ranked list truncation/dataset/bm25_test.pkl', 'rb') as f:\n",
    "    bm25_test = pickle.load(f)\n",
    "with open('./ranked list truncation/dataset/drmm_tks_train.pkl', 'rb') as f:\n",
    "    tks_train = pickle.load(f)\n",
    "with open('./ranked list truncation/dataset/drmm_tks_test.pkl', 'rb') as f:\n",
    "    tks_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取用到的所有doc id，在后续的计算中节省时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 261.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "doc_set = set()\n",
    "for dataset in tqdm([drmm_train, drmm_test, bm25_train, bm25_test, tks_train, tks_test]):\n",
    "    for qid in dataset:\n",
    "        docs = list(dataset[qid].keys())\n",
    "        doc_set.update(docs)\n",
    "print(len(doc_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "FT944-610 0.889916\n",
      "FBIS3-25845 0.879761\n",
      "LA030689-0004 0.871522\n",
      "LA012189-0056 0.870184\n",
      "LA030989-0104 0.864167\n"
     ]
    }
   ],
   "source": [
    "print(type(drmm_train['612']))\n",
    "for index, key in enumerate(drmm_train['612']):\n",
    "    print(key, drmm_train['612'][key])\n",
    "    if index == 4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需的统计特征\n",
    "\n",
    "* 根据特征分析，我们认为document length和unique token的数量事实上可以被tf-idf特征所完整描述\n",
    "\n",
    "* 如上所述，我们在这里去掉document length和unique token的统计，只做tf-idf和word2vec的统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranked list truncation/data_prep/statics/tfidf.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "with open('./ranked list truncation/data_prep/statics/doc2vec.pkl', 'rb') as f:\n",
    "    doc2vec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf稀疏表示的dense化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iv2dense(iv, total: int=231448):\n",
    "    dense = [0] * total\n",
    "    for item in iv:\n",
    "        dense[item[0]] = item[1]\n",
    "    return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105439/105439 [06:37<00:00, 265.43it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_dense = {}\n",
    "for doc in tqdm(doc_set):\n",
    "    tfidf_dense[doc] = iv2dense(tfidf[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranked list truncation/data_prep/statics/tfidf_dense.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_dense, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bicut统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [12:46<00:00,  4.03s/it]\n",
      "100%|██████████| 50/50 [02:30<00:00,  3.02s/it]\n",
      "100%|██████████| 193/193 [09:48<00:00,  3.05s/it]\n",
      "100%|██████████| 50/50 [02:32<00:00,  3.05s/it]\n",
      "100%|██████████| 194/194 [13:00<00:00,  4.02s/it]\n",
      "100%|██████████| 49/49 [02:29<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.mkdir('./ranked list truncation/dataset/bicut/bm25_train/')\n",
    "for qid in tqdm(bm25_train):\n",
    "    stats = []\n",
    "    for doc in bm25_train[qid]:\n",
    "        doc_stats = [bm25_train[qid][doc]] + tfidf_dense[doc]\n",
    "        stats.append(doc_stats)\n",
    "    with open('./ranked list truncation/dataset/bicut/bm25_train/{}.pkl'.format(qid), 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "\n",
    "os.mkdir('./ranked list truncation/dataset/bicut/bm25_test/')\n",
    "for qid in tqdm(bm25_test):\n",
    "    stats = []\n",
    "    for doc in bm25_test[qid]:\n",
    "        doc_stats = [bm25_test[qid][doc]] + tfidf_dense[doc]\n",
    "        stats.append(doc_stats)\n",
    "    with open('./ranked list truncation/dataset/bicut/bm25_test/{}.pkl'.format(qid), 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "\n",
    "os.mkdir('./ranked list truncation/dataset/bicut/drmm_train/')\n",
    "for qid in tqdm(drmm_train):\n",
    "    stats = []\n",
    "    for doc in drmm_train[qid]:\n",
    "        doc_stats = [drmm_train[qid][doc]] + tfidf_dense[doc]\n",
    "        stats.append(doc_stats)\n",
    "    with open('./ranked list truncation/dataset/bicut/drmm_train/{}.pkl'.format(qid), 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "\n",
    "os.mkdir('./ranked list truncation/dataset/bicut/drmm_test/')\n",
    "for qid in tqdm(drmm_test):\n",
    "    stats = []\n",
    "    for doc in drmm_test[qid]:\n",
    "        doc_stats = [drmm_test[qid][doc]] + tfidf_dense[doc]\n",
    "        stats.append(doc_stats)\n",
    "    with open('./ranked list truncation/dataset/bicut/drmm_test/{}.pkl'.format(qid), 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "\n",
    "os.mkdir('./ranked list truncation/dataset/bicut/drmm_tks_train/')\n",
    "for qid in tqdm(tks_train):\n",
    "    stats = []\n",
    "    for doc in tks_train[qid]:\n",
    "        doc_stats = [tks_train[qid][doc]] + tfidf_dense[doc]\n",
    "        stats.append(doc_stats)\n",
    "    with open('./ranked list truncation/dataset/bicut/drmm_tks_train/{}.pkl'.format(qid), 'wb') as f:\n",
    "        pickle.dump(stats, f)\n",
    "\n",
    "os.mkdir('./ranked list truncation/dataset/bicut/drmm_tks_test/')\n",
    "for qid in tqdm(tks_test):\n",
    "    stats = []\n",
    "    for doc in tks_test[qid]:\n",
    "        doc_stats = [tks_test[qid][doc]] + tfidf_dense[doc]\n",
    "        stats.append(doc_stats)\n",
    "    with open('./ranked list truncation/dataset/bicut/drmm_tks_test/{}.pkl'.format(qid), 'wb') as f:\n",
    "        pickle.dump(stats, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attncut统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_simi(x, y):\n",
    "    num = x.dot(y.T)\n",
    "    denom = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    sim = (num / denom) if denom != 0 else 0\n",
    "    return sim if not np.isnan(sim) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据数据集制作排序列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_list(dataset):\n",
    "    rl = {}\n",
    "    for qid in dataset:\n",
    "        rl[qid] = list(dataset[qid].keys())\n",
    "    return rl\n",
    "\n",
    "def simi_docs(doc0, doc1):\n",
    "    tfidf_doc0, tfidf_doc1 = np.array(tfidf_dense[doc0]), np.array(tfidf_dense[doc1])\n",
    "    d2v_doc0, d2v_doc1 = np.array(doc2vec[doc0]), np.array(doc2vec[doc1])\n",
    "    simi_tfidf = cos_simi(tfidf_doc0, tfidf_doc1)\n",
    "    simi_d2v = cos_simi(d2v_doc0, d2v_doc1)\n",
    "    return [simi_tfidf, simi_d2v]\n",
    "\n",
    "def simi_list(dataset):\n",
    "    rl = ranked_list(dataset)\n",
    "    sl = {}\n",
    "    for qid in tqdm(rl):\n",
    "        sl[qid] = [simi_docs(rl[qid][0], rl[qid][1])]\n",
    "        for i in range(1, 299):\n",
    "            simi_0 = simi_docs(rl[qid][i-1], rl[qid][i])\n",
    "            simi_1 = simi_docs(rl[qid][i], rl[qid][i+1])\n",
    "            simi = [(simi_0[0] + simi_1[0]) / 2, (simi_0[1] + simi_1[1]) / 2]\n",
    "            sl[qid].append(simi)\n",
    "        sl[qid].append(simi_docs(rl[qid][298], rl[qid][299]))\n",
    "    return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [2:35:33<00:00, 49.12s/it]\n",
      "100%|██████████| 50/50 [41:02<00:00, 49.24s/it]\n",
      "100%|██████████| 193/193 [2:41:30<00:00, 50.21s/it]\n",
      "100%|██████████| 50/50 [41:00<00:00, 49.20s/it]\n",
      "100%|██████████| 194/194 [2:39:04<00:00, 49.20s/it]\n",
      "100%|██████████| 49/49 [40:12<00:00, 49.23s/it]\n"
     ]
    }
   ],
   "source": [
    "bm25_train_sl = simi_list(bm25_train)\n",
    "with open('./ranked list truncation/dataset/attncut/bm25_train.pkl', 'wb') as f:\n",
    "    pickle.dump(bm25_train_sl, f)\n",
    "\n",
    "bm25_test_sl = simi_list(bm25_test)\n",
    "with open('./ranked list truncation/dataset/attncut/bm25_test.pkl', 'wb') as f:\n",
    "    pickle.dump(bm25_test_sl, f)\n",
    "\n",
    "drmm_train_sl = simi_list(drmm_train)\n",
    "with open('./ranked list truncation/dataset/attncut/drmm_train.pkl', 'wb') as f:\n",
    "    pickle.dump(drmm_train_sl, f)\n",
    "\n",
    "drmm_test_sl = simi_list(drmm_test)\n",
    "with open('./ranked list truncation/dataset/attncut/drmm_test.pkl', 'wb') as f:\n",
    "    pickle.dump(drmm_test_sl, f)\n",
    "\n",
    "drmm_tks_train_sl = simi_list(tks_train)\n",
    "with open('./ranked list truncation/dataset/attncut/drmm_tks_train.pkl', 'wb') as f:\n",
    "    pickle.dump(drmm_tks_train_sl, f)\n",
    "\n",
    "drmm_tks_test_sl = simi_list(tks_test)\n",
    "with open('./ranked list truncation/dataset/attncut/drmm_tks_test.pkl', 'wb') as f:\n",
    "    pickle.dump(drmm_tks_test_sl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}