{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "conda-env-ML-py",
   "display_name": "Python [conda env:ML] *",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch as t\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranked list truncation/data_prep/my_results/BM25_results/split_1/BM25_train_s1.pkl', 'rb') as f: train_data_raw = pickle.load(f)\n",
    "\n",
    "with open('./ranked list truncation/data_prep/my_results/BM25_results/split_1/BM25_test_s1.pkl', 'rb') as f: test_data_raw = pickle.load(f)\n",
    "\n",
    "with open('./ranked list truncation/data_prep/robust04_data/robust04_gt.pkl', 'rb') as f: gt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'doc_id': 'FBIS3-21961',\n",
       " 'rank': 1,\n",
       " 'bm25_score': 5.67759784,\n",
       " 'norm_bm25_score': 3.2061266261914216,\n",
       " 'is_relevant': True}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_data_raw['301']['retrieved_documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "for key in train_data_raw:\n",
    "    scores = [train_data_raw[key]['retrieved_documents'][i]['norm_bm25_score'] for i in range(300)]\n",
    "    is_rel = [1 if train_data_raw[key]['retrieved_documents'][i]['is_relevant'] else 0 for i in range(300)]\n",
    "    X_train.append(scores)\n",
    "    y_train.append(is_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = t.unsqueeze(t.Tensor(X_train), dim=1)\n",
    "y_train = t.Tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ranked list truncation/data_prep/my_results/drmm_tks_results/split_1/drmm_tks_train_s1.pkl', 'rb') as f: train_data_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'doc_id': 'FBIS3-41131', 'score': 6.436135292053223}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "train_data_raw['301'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "a = t.Tensor([[1], [2], [3]])\n",
    "b = t.sum(a[:2])\n",
    "b / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if t.tensor(0) == 0: print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 4., 4.])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "f = lambda x, *y: x ** 2\n",
    "a.map_(a, f)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.1999e+00],\n",
       "         [-8.7357e-01],\n",
       "         [-2.8038e-02]],\n",
       "\n",
       "        [[ 1.5940e+00],\n",
       "         [-3.9927e-04],\n",
       "         [-1.4029e+00]]])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch as t\n",
    "a = t.randn(2, 3, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = t.randn(2, 3, 4)\n",
    "a = t.cat((a, b), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.1999e+00,  7.5063e-01, -4.7991e-01, -2.8267e-01,  1.0497e+00],\n",
       "         [-8.7357e-01, -1.5994e+00,  1.1305e+00, -9.9166e-01,  1.5842e+00],\n",
       "         [-2.8038e-02, -5.1788e-01, -5.9645e-01,  1.8467e+00,  9.8149e-01]],\n",
       "\n",
       "        [[ 1.5940e+00, -4.8038e-01, -1.3766e+00, -3.9622e-01,  7.0838e-01],\n",
       "         [-3.9927e-04,  1.0944e-01,  1.7177e+00, -1.2022e+00,  3.1233e-01],\n",
       "         [-1.4029e+00, -7.2118e-01,  1.5183e+00,  2.2340e-01,  7.8001e-01]]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "source": [
    "##  bicut数据分query存储"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BM25_BASE = '/home/LAB/wangd/graduation_project/ranked list truncation/data_prep/my_results/BM25_results'\n",
    "DRMM_BASE = '/home/LAB/wangd/graduation_project/ranked list truncation/data_prep/my_results/drmm_results'\n",
    "DRMM_TKS_BASE = '/home/LAB/wangd/graduation_project/ranked list truncation/data_prep/my_results/drmm_tks_results'\n",
    "STATS_BASE = '/home/LAB/wangd/graduation_project/ranked list truncation/data_prep/statics'\n",
    "GT_PATH = '/home/LAB/wangd/graduation_project/ranked list truncation/data_prep/robust04_data/robust04_gt.pkl'\n",
    "\n",
    "def data_prepare(dataset_name: str, split: int):\n",
    "    if dataset_name == 'BM25':\n",
    "        with open('{}/split_{}/BM25_train_s{}.pkl'.format(BM25_BASE, split, split), 'rb') as f:\n",
    "            train_data_raw = pickle.load(f)\n",
    "        with open('{}/split_{}/BM25_test_s{}.pkl'.format(BM25_BASE, split, split), 'rb') as f:\n",
    "            test_data_raw = pickle.load(f)\n",
    "        with open('{}/bicut_bm25_input.pkl'.format(STATS_BASE), 'rb') as f:\n",
    "            stats_bm25 = pickle.load(f)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = [], [], [], []\n",
    "        for key in train_data_raw:\n",
    "            scores = np.array([train_data_raw[key]['retrieved_documents'][i]['norm_bm25_score']\n",
    "                        for i in range(300)])\n",
    "            stats = np.array(stats_bm25[key])\n",
    "            input_features = np.column_stack((scores, stats))\n",
    "            is_rel = [1 if train_data_raw[key]['retrieved_documents'][i]['is_relevant'] else 0\n",
    "                        for i in range(300)]\n",
    "            if not os.path.exits('{}/bicut_bm25_s{}_train/'.format(STATS_BASE, split)): \n",
    "                os.mkdir('{}/bicut_bm25_s{}_train/'.format(STATS_BASE, split))\n",
    "            with open('{}/bicut_bm25_s{}_train/qid_{}.pkl'.format(STATS_BASE, split, key), 'wb') as f:\n",
    "                pickle.dump((input_features, is_rel), f)\n",
    "\n",
    "        for key in test_data_raw:\n",
    "            scores = np.array([test_data_raw[key]['retrieved_documents'][i]['norm_bm25_score']\n",
    "                        for i in range(300)])\n",
    "            stats = np.array(stats_bm25[key])\n",
    "            input_features = np.column_stack((scores, stats))\n",
    "            is_rel = [1 if test_data_raw[key]['retrieved_documents'][i]['is_relevant'] else 0\n",
    "                        for i in range(300)]\n",
    "            if not os.path.exits('{}/bicut_bm25_s{}_test/'.format(STATS_BASE, split)): \n",
    "                os.mkdir('{}/bicut_bm25_s{}_test/'.format(STATS_BASE, split))\n",
    "            with open('{}/bicut_bm25_s{}_test/qid_{}.pkl'.format(STATS_BASE, split, key), 'wb') as f:\n",
    "                pickle.dump((input_features, is_rel), f)\n",
    "\n",
    "    elif dataset_name == 'DRMM':\n",
    "        with open('{}/split_{}/drmm_train_s{}.pkl'.format(DRMM_BASE, split, split), 'rb') as f:\n",
    "            train_data_raw = pickle.load(f)\n",
    "        with open('{}/split_{}/drmm_test_s{}.pkl'.format(DRMM_BASE, split, split), 'rb') as f:\n",
    "            test_data_raw = pickle.load(f)\n",
    "        with open('{}/bicut_drmm_input.pkl'.format(STATS_BASE), 'rb') as f:\n",
    "            stats_drmm = pickle.load(f)\n",
    "        with open(GT_PATH, 'rb') as f:\n",
    "            gt = pickle.load(f)\n",
    "            for key in gt:\n",
    "                gt[key] = set(gt[key])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = [], [], [], []\n",
    "        for key in train_data_raw:\n",
    "            scores = np.array([train_data_raw[key][i]['score'] for i in range(300)])\n",
    "            stats = np.array(stats_drmm[key])\n",
    "            input_features = np.column_stack((scores, stats))\n",
    "            is_rel = [1 if train_data_raw[key][i]['doc_id'] in gt[key] else 0\n",
    "                        for i in range(300)]\n",
    "            if not os.path.exits('{}/bicut_drmm_s{}_train/'.format(STATS_BASE, split)): \n",
    "                os.mkdir('{}/bicut_drmm_s{}_train/'.format(STATS_BASE, split))\n",
    "            with open('{}/bicut_drmm_s{}_train/qid_{}.pkl'.format(STATS_BASE, split, key), 'wb') as f:\n",
    "                pickle.dump((input_features, is_rel), f)\n",
    "        \n",
    "        for key in test_data_raw:\n",
    "            scores = np.arange([test_data_raw[key][i]['score'] for i in range(300)])\n",
    "            stats = np.array(stats_drmm[key])\n",
    "            input_features = np.column_stack((scores, stats))\n",
    "            is_rel = [1 if test_data_raw[key][i]['doc_id'] in gt[key] else 0\n",
    "                        for i in range(300)]\n",
    "            X_test.append(input_features.tolist())\n",
    "            y_test.append(is_rel)\n",
    "            if not os.path.exits('{}/bicut_drmm_s{}_test/'.format(STATS_BASE, split)): \n",
    "                os.mkdir('{}/bicut_drmm_s{}_test/'.format(STATS_BASE, split))\n",
    "            with open('{}/bicut_drmm_s{}_test/qid_{}.pkl'.format(STATS_BASE, split, key), 'wb') as f:\n",
    "                pickle.dump((input_features, is_rel), f)"
   ]
  }
 ]
}